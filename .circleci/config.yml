version: 2.1

commands:
  install-uv:
    steps:
      - run:
          name: Install uv + sync environment
          command: |
            python -m pip install --upgrade pip
            python -m pip install uv
            uv sync --locked --frozen --lockfile uv.lock
  dbt-deps:
    steps:
      - run:
          name: Install dbt deps
          command: uv run dbt deps --project-dir $DBT_PROJECT_DIR


jobs:

  integration-tests-core:
    docker:
      - image: cimg/python:3.9.9
      - image: cimg/postgres:14.0

    resource_class: small

    environment:
      DBT_PROFILES_DIR: ./src/integration_tests/ci
      DBT_PROJECT_DIR: ./src/integration_tests
      BIGQUERY_SERVICE_KEY_PATH: "/home/circleci/bigquery-service-key.json"

    steps:
      - checkout
      - install-uv
      - dbt-deps

      - run:
          name: Run tests - Postgres
          environment:
            POSTGRES_HOST: localhost
            POSTGRES_TEST_USER: postgres
            POSTGRES_TEST_PASSWORD: ''
            POSTGRES_TEST_PORT: 5432
            POSTGRES_TEST_DATABASE: circle_test
            POSTGRES_TEST_SCHEMA: versioned_scd_integration_tests
          command: uv run dbt build -t postgres --project-dir $DBT_PROJECT_DIR

      - run:
          name: Set up GCP credentials
          command: |
            echo "Writing to $BIGQUERY_SERVICE_KEY_PATH"
            echo "$BIGQUERY_SERVICE_KEY" > "$BIGQUERY_SERVICE_KEY_PATH"
            stat -c%s "$BIGQUERY_SERVICE_KEY_PATH"

      - run:
          name: Run tests - BigQuery
          command: uv run dbt build -t bigquery --project-dir $DBT_PROJECT_DIR

      - run:
          name: Run tests - Snowflake
          command: uv run dbt build -t snowflake --project-dir $DBT_PROJECT_DIR

      - run:
          name: Run tests - DuckDB
          command: uv run dbt build -t duckdb --project-dir $DBT_PROJECT_DIR

      - store_artifacts:
          path: ./logs


  integration-tests-spark-thrift:
    docker:
      - image: cimg/python:3.9.9
      - image: godatadriven/spark:3.1.1
        environment:
          WAIT_FOR: localhost:5432
        command: >
          --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2
          --name Thrift JDBC/ODBC Server
      - image: postgres:9.6.17-alpine
        environment:
          POSTGRES_USER: dbt
          POSTGRES_PASSWORD: dbt
          POSTGRES_DB: metastore

    resource_class: small

    environment:
      DBT_PROFILES_DIR: ./src/integration_tests/ci
      DBT_PROJECT_DIR: ./src/integration_tests

    steps:
      - checkout
      - run:
          name: Install system libraries
          command: |
            sudo apt-get update
            sudo apt-get install -y libsasl2-dev libsasl2-2
      - install-uv
      - dbt-deps

      - run:
          name: Wait for Spark-Thrift Server
          command: dockerize -wait tcp://localhost:10000 -timeout 15m -wait-retry-interval 5s

      - run:
          name: Run tests - Spark
          command: uv run dbt build -t spark --project-dir $DBT_PROJECT_DIR

      - store_artifacts:
          path: ./logs


  integration-tests-trino:
    docker:
      - image: cimg/python:3.11
      - image: trinodb/trino:432

    resource_class: small

    environment:
      DBT_PROFILES_DIR: ./src/integration_tests/ci
      DBT_PROJECT_DIR: ./src/integration_tests

    steps:
      - checkout
      - install-uv
      - dbt-deps
      - setup_remote_docker

      - run:
          name: Run Trino server
          command: |
            docker run --name trino -p 8080:8080 -d \
              -v `pwd`/integration_tests/docker/trino/catalog:/etc/trino/catalog \
              trinodb/trino:432
            timeout 5m bash -c 'while ! docker logs trino 2>&1 | grep "SERVER STARTED"; do sleep 2; done'

      - run:
          name: Run tests - Trino
          command: uv run dbt build -t trino --project-dir $DBT_PROJECT_DIR



workflows:
  version: 2
  test-all:
    jobs:
      - hold:
          type: approval
      - integration-tests-core:
          requires: [hold]
      - integration-tests-spark-thrift:
          requires: [hold]
      - integration-tests-trino:
          requires: [hold]

